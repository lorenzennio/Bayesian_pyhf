{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "# import aesara\n",
    "import aesara.tensor as at\n",
    "# from aesara.graph.op import Op\n",
    "from aesara.link.jax.dispatch import jax_funcify\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(1, '/Users/malinhorstmann/Documents/pyhf_pymc/src')\n",
    "import MH_inference\n",
    "import HMC_inference\n",
    "import prepare_inference\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple pyhf model\n",
    "model = pyhf.Model(\n",
    "    {'channels': [{'name': 'singlechannel',\n",
    "    'samples': [\n",
    "    {'name': 'signal',\n",
    "     'data': [6, 6, 60],\n",
    "     'modifiers': [\n",
    "         {'name': 'mu', 'type': 'normfactor', 'data': None}]},\n",
    "\n",
    "    {'name': 'background',\n",
    "     'data': [55, 55, 55],\n",
    "     'modifiers': [\n",
    "        ## Staterror / Normal\n",
    "        {\"name\": \"my_staterror\",\"type\": \"staterror\",\"data\": [2.0, 2.0, 2.0],},\n",
    "        ## Lumi / Normal\n",
    "        {'name': 'lumi', 'type': 'lumi', 'data': None},\n",
    "        ## Correlated / Normal\n",
    "        {'name': 'corr_bkg', 'type': 'histosys','data': {'hi_data': [65, 56, 67], 'lo_data': [40, 40, 43]}},\n",
    "        {'name': 'corr_bkg1', 'type': 'histosys','data': {'hi_data': [65, 56, 67], 'lo_data': [40, 40, 43]}},\n",
    "        {'name': 'corr_bkg2', 'type': 'histosys','data': {'hi_data': [65, 56, 67], 'lo_data': [40, 40, 43]}},\n",
    "        ## Uncorrelated / Poisson\n",
    "        {'name': 'uncorr_bkg', 'type': 'shapesys','data': [7, 8, 7.17]},\n",
    "        {'name': 'uncorr_bkg1', 'type': 'shapesys','data': [7, 8, 7.17]},\n",
    "        {'name': 'uncorr_bkg2', 'type': 'shapesys','data': [7, 8, 7.17]},\n",
    "        \n",
    "         ]},    \n",
    "                                 \n",
    "    ]},\n",
    "    ]\n",
    "    ,\n",
    "    \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"lumi\",\n",
    "                \"auxdata\": [1.0],\n",
    "                \"sigmas\": [0.017],\n",
    "                \"bounds\": [[0.915, 1.085]],\n",
    "                \"inits\": [1.0],\n",
    "            }],\n",
    "        }\n",
    ")\n",
    "\n",
    "obs = model.expected_actualdata(model.config.suggested_init())\n",
    "\n",
    "nBins = len(model.expected_actualdata(model.config.suggested_init()))\n",
    "nPars = len(model.config.suggested_init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SRee_SRmm_Srem.json') as serialized:\n",
    "with open('ttbar_ljets_xsec_inclusive_pruned.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "model = workspace.model()\n",
    "\n",
    "obs = workspace.data(model, include_auxdata=False)\n",
    "\n",
    "nBins = len(model.expected_actualdata(model.config.suggested_init()))\n",
    "nPars = len(model.config.suggested_init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the priors for sampling\n",
    "    # Unconstrained parameters\n",
    "unconstr_dict = {\n",
    "    'uncon1': {'type': 'unconstrained', 'type2': 'normal', 'input': [[1], [0.1]]}\n",
    "    }\n",
    "\n",
    "    # Create dictionary with all priors (unconstrained, constrained by normal and poisson)\n",
    "prior_dict = prepare_inference.prepare_priors(model, unconstr_dict)\n",
    "\n",
    "    # dictionary with keys 'model', 'obs', 'priors', 'precision'\n",
    "prepared_model = prepare_inference.prepare_model(model=model, observations=obs, precision=1, priors=prior_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jax expected data\n",
    "@jax.jit\n",
    "def processed_expData(parameters):\n",
    "    a = jnp.stack([model.expected_actualdata(parameters)[i] for i in range(nBins)])\n",
    "    return a\n",
    "\n",
    "one_vector = np.full(nBins, 1., dtype='float64')\n",
    "\n",
    "# Gradient list (dn_bins/dx_1, ..., dn_bins/dx_nPars)\n",
    "@jax.jit\n",
    "def vjp_expData(parameters):\n",
    "    _,back = jax.vjp(processed_expData, parameters)\n",
    "    return back(one_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter options\n",
    "eval_point = model.config.suggested_init()\n",
    "pars = prepare_inference.priors2pymc(prepared_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian MC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Op\n",
    "\n",
    "Takes both eval_point and pars as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VJPOp(pt.Op):\n",
    "\n",
    "    def make_node(self, parameters):\n",
    "        # self.vjp_func = vjp_expData\n",
    "        inputs = [pt.as_tensor_variable(parameters)]\n",
    "        outputs = [pt.vector()]\n",
    "        \n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (parameters,) = inputs\n",
    "        results = vjp_expData(parameters)\n",
    "\n",
    "        if not isinstance(results, (list, tuple)):\n",
    "                results = (results,)\n",
    "                \n",
    "        for i, r in enumerate(results):\n",
    "            outputs[i][0] = np.asarray(r)\n",
    "\n",
    "vjp_op = VJPOp()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Gradient Op\n",
    "\n",
    "Takes both eval_point and pars as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpDataOp(pt.Op):\n",
    "    \n",
    "    def make_node(self, parameters):\n",
    "        inputs = [pt.as_tensor_variable(parameters)]\n",
    "        outputs = [pt.vector()]\n",
    "\n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (parameters, ) = inputs\n",
    "        results = processed_expData(parameters)\n",
    "\n",
    "        if len(outputs) == 1:\n",
    "                outputs[0][0] = np.asarray(results)\n",
    "                return\n",
    "        for i, r in enumerate(results):\n",
    "                outputs[i][0] = np.asarray(r)\n",
    "\n",
    "    # def grad(self, parameters):\n",
    "    #     return [vjp_op(parameters)]\n",
    "        \n",
    "expData_op = ExpDataOp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ExpDataOp(pt.Op):\n",
    "#     \"\"\"\n",
    "\n",
    "#     \"\"\"\n",
    "#     itypes = [pt.dvector]  \n",
    "#     otypes = [pt.dvector]  \n",
    "\n",
    "#     # def __init__(self, name, func):\n",
    "#     #     ## Add inputs as class attributes\n",
    "#     #     self.func = func\n",
    "#     #     self.name = name\n",
    "\n",
    "#     def perform(self, node, inputs, outputs):\n",
    "#         ## Method that is used when calling the Op\n",
    "#         (theta,) = inputs  # Contains my variables\n",
    "\n",
    "#         ## Calling input function (in our case the model.expected_actualdata)\n",
    "#         result = self.func(theta)\n",
    "\n",
    "#         ## Output values of model.expected_actualdata\n",
    "#         outputs[0][0] = np.asarray(result, dtype=node.outputs[0].dtype)\n",
    "\n",
    "#     def grad(self, parameters):\n",
    "#         return [vjp_op(parameters)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Unconstrained, Normals, Gammas]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_500 draw iterations (4_000 + 6_000 draws total) took 2 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [ExpData, Gammas, Normals, Unconstrained]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61.  61. 115.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malinhorstmann/anaconda3/envs/pyhf_pymc/lib/python3.9/site-packages/arviz/stats/stats.py:1351: UserWarning: Selecting first found group: posterior_predictive\n",
      "  warnings.warn(f\"Selecting first found group: {data.groups()[0]}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExpData[0]</th>\n",
       "      <td>60.990</td>\n",
       "      <td>0.994</td>\n",
       "      <td>59.186</td>\n",
       "      <td>62.935</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.009</td>\n",
       "      <td>6053.0</td>\n",
       "      <td>5928.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExpData[1]</th>\n",
       "      <td>60.983</td>\n",
       "      <td>0.993</td>\n",
       "      <td>59.140</td>\n",
       "      <td>62.814</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.009</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>5930.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExpData[2]</th>\n",
       "      <td>115.011</td>\n",
       "      <td>0.993</td>\n",
       "      <td>113.126</td>\n",
       "      <td>116.858</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.009</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean     sd   hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "ExpData[0]   60.990  0.994   59.186   62.935      0.013    0.009    6053.0   \n",
       "ExpData[1]   60.983  0.993   59.140   62.814      0.013    0.009    5896.0   \n",
       "ExpData[2]  115.011  0.993  113.126  116.858      0.013    0.009    5704.0   \n",
       "\n",
       "            ess_tail  r_hat  \n",
       "ExpData[0]    5928.0    1.0  \n",
       "ExpData[1]    5930.0    1.0  \n",
       "ExpData[2]    5712.0    1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model():\n",
    "    pars = prepare_inference.priors2pymc(prepared_model)\n",
    "    pars = model.config.suggested_init()\n",
    "\n",
    "    expData_op = ExpDataOp()\n",
    "    ExpData = pm.Normal(\"ExpData\", mu=expData_op(pars).eval(), sigma=1, observed=obs)\n",
    "\n",
    "    post_data = pm.sample(1500)\n",
    "    post_pred = pm.sample_posterior_predictive(post_data)\n",
    "    prior_pred = pm.sample_prior_predictive(1500)\n",
    "\n",
    "print(model.expected_actualdata(model.config.suggested_init()))\n",
    "az.summary(post_pred, var_names=\"ExpData\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings\n",
    "\n",
    "### Non-Gradient Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpDataOp_MH1(pt.Op):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    itypes = [pt.dvector]  \n",
    "    otypes = [pt.dvector]  \n",
    "\n",
    "    def __init__(self, name, func):\n",
    "        ## Add inputs as class attributes\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        ## Method that is used when calling the Op\n",
    "        (theta,) = inputs  # Contains my variables\n",
    "\n",
    "        ## Calling input function (in our case the model.expected_actualdata)\n",
    "        result = self.func(theta)\n",
    "\n",
    "        ## Output values of model.expected_actualdata\n",
    "        outputs[0][0] = np.asarray(result, dtype=node.outputs[0].dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [Unconstrained]\n",
      ">Metropolis: [Normals]\n",
      ">Metropolis: [Gammas]\n",
      "CompoundStep\n",
      ">Metropolis: [Unconstrained]\n",
      ">Metropolis: [Normals]\n",
      ">Metropolis: [Gammas]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 1 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [ExpData, Gammas, Normals, Unconstrained]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61.  61. 115.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malinhorstmann/anaconda3/envs/pyhf_pymc/lib/python3.9/site-packages/arviz/stats/stats.py:1351: UserWarning: Selecting first found group: posterior_predictive\n",
      "  warnings.warn(f\"Selecting first found group: {data.groups()[0]}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExpData[0]</th>\n",
       "      <td>61.179</td>\n",
       "      <td>1.403</td>\n",
       "      <td>58.425</td>\n",
       "      <td>63.645</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>798.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExpData[1]</th>\n",
       "      <td>60.708</td>\n",
       "      <td>1.454</td>\n",
       "      <td>58.094</td>\n",
       "      <td>63.426</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.046</td>\n",
       "      <td>507.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExpData[2]</th>\n",
       "      <td>115.070</td>\n",
       "      <td>1.423</td>\n",
       "      <td>112.616</td>\n",
       "      <td>117.905</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.041</td>\n",
       "      <td>614.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean     sd   hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "ExpData[0]   61.179  1.403   58.425   63.645      0.050    0.035     798.0   \n",
       "ExpData[1]   60.708  1.454   58.094   63.426      0.065    0.046     507.0   \n",
       "ExpData[2]  115.070  1.423  112.616  117.905      0.057    0.041     614.0   \n",
       "\n",
       "            ess_tail  r_hat  \n",
       "ExpData[0]    1381.0    1.0  \n",
       "ExpData[1]     726.0    1.0  \n",
       "ExpData[2]    1068.0    1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model():\n",
    "\n",
    "    pars = prepare_inference.priors2pymc(prepared_model)\n",
    "    # pars = eval_point\n",
    "    \n",
    "    ExpData_op_MH = ExpDataOp_MH1('mainOp', jax.jit(model.expected_actualdata))\n",
    "\n",
    "    ExpData_MH = pm.Normal('ExpData', mu=ExpData_op_MH(pars), sigma=1, observed=obs)\n",
    "\n",
    "    post_data_MH = pm.sample(500)\n",
    "    post_pred_MH = pm.sample_posterior_predictive(post_data_MH)\n",
    "    prior_pred_MH = pm.sample_prior_predictive(500)\n",
    "\n",
    "print(model.expected_actualdata(model.config.suggested_init()))\n",
    "az.summary(post_pred_MH, var_names=\"ExpData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
