{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "# import aesara\n",
    "import aesara.tensor as at\n",
    "# from aesara.graph.op import Op\n",
    "from aesara.link.jax.dispatch import jax_funcify\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(1, '/Users/malinhorstmann/Documents/pyhf_pymc/src')\n",
    "import MH_inference\n",
    "import HMC_inference\n",
    "import prepare_inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SRee_SRmm_Srem.json') as serialized:\n",
    "# with open('ttbar_ljets_xsec_inclusive_pruned.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "model = workspace.model()\n",
    "obs = workspace.data(model, include_auxdata=False)\n",
    "nBins = len(model.expected_actualdata(model.config.suggested_init()))\n",
    "nPars = len(model.config.suggested_init())\n",
    "\n",
    "# Prepare the priors for sampling\n",
    "    # Unconstrained parameters\n",
    "unconstr_dict = {\n",
    "    'uncon1': {'type': 'unconstrained', 'type2': 'normal', 'input': [[1], [0.1]]}\n",
    "    }\n",
    "\n",
    "    # Create dictionary with all priors (unconstrained, constrained by normal and poisson)\n",
    "prior_dict = prepare_inference.prepare_priors(model, unconstr_dict)\n",
    "\n",
    "    # dictionary with keys 'model', 'obs', 'priors', 'precision'\n",
    "\n",
    "prepared_model = prepare_inference.prepare_model(model=model, observations=obs, precision=0.10, priors=prior_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def processed_expData(parameters):\n",
    "    # a = jnp.stack([jax.jit(model.expected_actualdata(p))[i] for i in range(nBins)])\n",
    "    a = jnp.stack([model.expected_actualdata(parameters)[i] for i in range(nBins)])\n",
    "    return a\n",
    "\n",
    "@jax.jit\n",
    "def vjp_expData(parameters, vector):\n",
    "    _,back = jax.vjp(processed_expData, parameters)\n",
    "    return back(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, (18,))\n"
     ]
    }
   ],
   "source": [
    "one_vector = np.full(nBins, 1., dtype='float64')\n",
    "\n",
    "pars = prepare_inference.priors2pymc(prepared_model)\n",
    "print(pars.type)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Version\n",
    "\n",
    " - Attention: Input and Output length of `VJPCustomOp(Op)` are super random. I have to add this weird `x`\n",
    " by hand, in order to have a three-dim output for `VJPCustomOp()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VJPCustomOp(Op):\n",
    "\n",
    "    def make_node(self, vjp_func, parameters, vector):\n",
    "        a = np.linspace(0.01, 1, nBins).tolist()\n",
    "        # a = model.config.suggested_init()\n",
    "        # pars = at.as_tensor_variable(a)\n",
    "        self.vjp_func = vjp_expData\n",
    "        inputs = [pt.as_tensor_variable(a), pt.as_tensor_variable(vector)]\n",
    "        outputs = [inputs[0].type()]\n",
    "        \n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (parameters, vector) = inputs\n",
    "        results = vjp_expData(parameters, vector)\n",
    "\n",
    "        if not isinstance(results, (list, tuple)):\n",
    "                results = (results,)\n",
    "                \n",
    "        for i, r in enumerate(results):\n",
    "            outputs[i][0] = np.asarray(r)\n",
    "\n",
    "vjp_custom_op = VJPCustomOp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, (18,))\n",
      "TensorType(float64, (18,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3844388  0.00761265 0.10609929]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [ehh]\n",
      "NUTS: [ehh]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 0 seconds.\n",
      "Sampling: [ehh]\n"
     ]
    }
   ],
   "source": [
    "# Testing if at-type tensors work\n",
    "a = np.linspace(0.01, 1, len(model.config.par_names)).tolist()\n",
    "pars = at.as_tensor_variable(a)\n",
    "print(pars.type)\n",
    "\n",
    "# Testing if pm-type Tensors work\n",
    "pars = prepare_inference.priors2pymc(prepared_model)\n",
    "print(pars.type)\n",
    "\n",
    "print(vjp_custom_op(vjp_func=vjp_expData, parameters=pars, vector=one_vector).eval())\n",
    "\n",
    "# Sampling the gradient\n",
    "with pm.Model():\n",
    "    # pars = prepare_inference.priors2pymc(prepared_model)\n",
    "    mu = vjp_custom_op(vjp_func=vjp_expData, parameters=pars, vector=one_vector).eval()\n",
    "    pm.Normal(\"ehh\", mu=mu, sigma=0.1)\n",
    "    post_data = pm.sample(500)\n",
    "    post_pred = pm.sample_posterior_predictive(post_data)\n",
    "    prior_pred = pm.sample_prior_predictive(500)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The non-gradient Op (with grad node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOp(Op):\n",
    "    \n",
    "    def make_node(self, func, parameters):\n",
    "        self.func = processed_expData\n",
    "        inputs = [pt.as_tensor_variable(parameters)]\n",
    "        outputs = [inputs[0].type()]\n",
    "\n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (parameters, ) = inputs\n",
    "        results = processed_expData(parameters)\n",
    "\n",
    "        if len(outputs) == 1:\n",
    "                outputs[0][0] = np.asarray(results)\n",
    "                return\n",
    "        for i, r in enumerate(results):\n",
    "                outputs[i][0] = np.asarray(r)\n",
    "\n",
    "    def grad(self, vjp_func, parameters, vector):\n",
    "        return [vjp_custom_op(vjp_func, parameters, vector)]\n",
    "        \n",
    "custom_op = CustomOp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, (18,))\n",
      "[0.3844388  0.00761265 0.10609929]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Unconstrained, Normals, ExpData]\n",
      "NUTS: [Unconstrained, Normals, ExpData]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 1 seconds.\n",
      "Sampling: [ExpData, Normals, Unconstrained]\n"
     ]
    }
   ],
   "source": [
    "# Testing if at-type tensors work\n",
    "# a = np.linspace(0.01, 1, len(model.config.par_names)).tolist()\n",
    "# pars = at.as_tensor_variable(a)\n",
    "# print(pars.type)\n",
    "\n",
    "# Testing if pm-type Tensors work\n",
    "pars = prepare_inference.priors2pymc(prepared_model)\n",
    "print(pars.type)\n",
    "\n",
    "print(custom_op.grad(processed_expData, pars, one_vector)[0].eval())\n",
    "\n",
    "with pm.Model():\n",
    "    pars = prepare_inference.priors2pymc(prepared_model)\n",
    "    mu = custom_op.grad(processed_expData, pars, one_vector)[0].eval()\n",
    "    pm.Normal(\"ExpData\", mu=mu, sigma=0.1)\n",
    "    \n",
    "    post_data = pm.sample(500)\n",
    "    post_pred = pm.sample_posterior_predictive(post_data)\n",
    "    prior_pred = pm.sample_prior_predictive(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47245307 0.01439832 0.2079121 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExpData[0]</th>\n",
       "      <td>0.384</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4037.0</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExpData[1]</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExpData[2]</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5539.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "ExpData[0]  0.384  0.100   0.194    0.565      0.002    0.001    4037.0   \n",
       "ExpData[1]  0.008  0.101  -0.185    0.187      0.002    0.003    4340.0   \n",
       "ExpData[2]  0.105  0.103  -0.090    0.288      0.001    0.002    5539.0   \n",
       "\n",
       "            ess_tail  r_hat  \n",
       "ExpData[0]    1616.0   1.01  \n",
       "ExpData[1]    1449.0   1.00  \n",
       "ExpData[2]    1489.0   1.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.expected_actualdata(a))\n",
    "az.summary(post_data, var_names=\"ExpData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
