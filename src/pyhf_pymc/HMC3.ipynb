{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "# import aesara\n",
    "import aesara.tensor as at\n",
    "# from aesara.graph.op import Op\n",
    "from aesara.link.jax.dispatch import jax_funcify\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(1, '/Users/malinhorstmann/Documents/pyhf_pymc/src')\n",
    "import MH_inference\n",
    "import HMC_inference\n",
    "import prepare_inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaced Leptons\n",
    "with open('SRee_SRmm_Srem.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "DL_model = workspace.model()\n",
    "DL_obs = workspace.data(DL_model, include_auxdata=False)\n",
    "DL_nBins = len(DL_model.expected_actualdata(DL_model.config.suggested_init()))\n",
    "\n",
    "# ttbar\n",
    "with open('ttbar_ljets_xsec_inclusive_pruned.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "ttbar_model = workspace.model()\n",
    "ttbar_obs = workspace.data(ttbar_model, include_auxdata=False)\n",
    "ttbar_nBins = len(DL_model.expected_actualdata(ttbar_model.config.suggested_init()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with all models\n",
    "# all_models = [['Dummy_Model', dummy_model, dummy_obs, dummy_nBins],     \n",
    "all_models = [['DisplacedLeptons', DL_model, DL_obs, DL_nBins], \n",
    "              ['ttbar', ttbar_model, ttbar_obs, ttbar_nBins]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model, obs, nBins in all_models:\n",
    "    # Supply information on the unconstrained parameters\n",
    "    unconstr_dict = {\n",
    "    'uncon1': {'type': 'unconstrained', 'type2': 'normal', 'input': [[1], [0.1]]}\n",
    "    }\n",
    "\n",
    "    # Create dictionary with all priors (unconstrained, constrained by normal and poisson)\n",
    "    prior_dict = prepare_inference.prepare_priors(model, unconstr_dict)\n",
    "\n",
    "    # dictionary with keys 'model', 'obs', 'priors', 'precision'\n",
    "    prepared_model = prepare_inference.prepare_model(model=model, observations=obs, precision=0.10, priors=prior_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
