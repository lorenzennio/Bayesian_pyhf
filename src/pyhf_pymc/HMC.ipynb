{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/malinhorstmann/Documents/pyhf_pymc/src')\n",
    "from pyhf_pymc import MH_inference\n",
    "from pyhf_pymc import HMC_inference\n",
    "from pyhf_pymc import prepare_inference\n",
    "\n",
    "import pytensor\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "import aesara\n",
    "import aesara.tensor as at\n",
    "from aesara.graph.op import Op\n",
    "from aesara.link.jax.dispatch import jax_funcify\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple pyhf model\n",
    "dummy_model = pyhf.Model(\n",
    "    {'channels': [{'name': 'singlechannel',\n",
    "    'samples': [\n",
    "    {'name': 'signal',\n",
    "     'data': [6, 6, 3],\n",
    "     'modifiers': [\n",
    "         {'name': 'mu', 'type': 'normfactor', 'data': None}]},\n",
    "\n",
    "    {'name': 'background',\n",
    "     'data': [55, 55, 55],''\n",
    "     'modifiers': [\n",
    "        ## Staterror / Normal\n",
    "        {\"name\": \"my_staterror\",\"type\": \"staterror\",\"data\": [2.0, 2.0, 2.4],},\n",
    "        ## Lumi / Normal\n",
    "        {'name': 'lumi', 'type': 'lumi', 'data': None},\n",
    "        ## Correlated / Normal\n",
    "        {'name': 'corr_bkg', 'type': 'histosys','data': {'hi_data': [65, 56, 67], 'lo_data': [40, 40, 43]}},\n",
    "        {'name': 'corr_bkg1', 'type': 'histosys','data': {'hi_data': [65, 65, 66], 'lo_data': [40, 40, 40]}},\n",
    "        {'name': 'corr_bkg2', 'type': 'histosys','data': {'hi_data': [66, 65, 60], 'lo_data': [40, 40, 39]}},\n",
    "        ## Uncorrelated / Poisson\n",
    "        # {'name': 'uncorr_bkg', 'type': 'shapesys','data': [7, 8, 7.17]},\n",
    "        # {'name': 'uncorr_bkg1', 'type': 'shapesys','data': [7, 8, 6.7]},\n",
    "        # {'name': 'uncorr_bkg2', 'type': 'shapesys','data': [7.27, 9, 7]},\n",
    "        \n",
    "         ]},    \n",
    "                                 \n",
    "    ]},\n",
    "    ],\n",
    "    \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"lumi\",\n",
    "                \"auxdata\": [1.0],\n",
    "                \"sigmas\": [0.017],\n",
    "                \"bounds\": [[0.915, 1.085]],\n",
    "                \"inits\": [1.0],\n",
    "            }\n",
    "        ],}\n",
    ")\n",
    "\n",
    "dummy_nBins = len(dummy_model.expected_actualdata(dummy_model.config.suggested_init()))\n",
    "\n",
    "### Observations\n",
    "dummy_obs = dummy_model.expected_actualdata(dummy_model.config.suggested_init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SRee_SRmm_Srem.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "DL_model = workspace.model()\n",
    "DL_obs = workspace.data(DL_model, include_auxdata=False)\n",
    "DL_nBins = len(DL_model.expected_actualdata(DL_model.config.suggested_init()))\n",
    "\n",
    "\n",
    "with open('ttbar_ljets_xsec_inclusive_pruned.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "ttbar_model = workspace.model()\n",
    "ttbar_obs = workspace.data(ttbar_model, include_auxdata=False)\n",
    "ttbar_nBins = len(ttbar_model.expected_actualdata(ttbar_model.config.suggested_init()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with DL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processedData(p):\n",
    "    # a = jnp.stack([jax.jit(model.expected_actualdata(p))[i] for i in range(nBins)])\n",
    "    a = jnp.stack([DL_model.expected_actualdata(p)[i] for i in range(DL_nBins)])\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Appling the Op to model.expected_actualdata\n",
    "op, grad_op = HMC_inference.make_op(\n",
    "    processedData,\n",
    "    (at.TensorType(dtype=np.float64, shape=(len(DL_model.config.par_map),)),),\n",
    "    (at.TensorType(dtype=np.float64, shape=(DL_nBins,)),),\n",
    ")\n",
    "\n",
    "a = np.linspace(0.01, 1, len(DL_model.config.par_names)).tolist()\n",
    "pars = at.as_tensor_variable(a)\n",
    "grad_op(pars, at.constant([1.0, 1.0, 1.0])).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstr_dict = {\n",
    "    'uncon1': {'type': 'unconstrained', 'type2': 'normal', 'input': [[1], [0.1]]}\n",
    "    }\n",
    "\n",
    "\n",
    "prior_dict = prepare_inference.prepare_priors(DL_model, unconstr_dict)\n",
    "\n",
    "    # dictionary with keys 'model', 'obs', 'priors', 'precision'\n",
    "prepared_model = prepare_inference.prepare_model(model=DL_model, observations=DL_obs, precision=0.10, priors=prior_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the `sampling()` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, (18,))\n"
     ]
    }
   ],
   "source": [
    "unconstr_pars, norm_pars, poiss_pars = [], [], []\n",
    "norm_mu, norm_sigma = [], []\n",
    "poiss_alpha, poiss_beta = [], []\n",
    "model = prepared_model['model']\n",
    "obs = prepared_model['obs']\n",
    "prior_dict = prepared_model['priors']\n",
    "precision = prepared_model['precision']\n",
    "\n",
    "with pm.Model():\n",
    "    \n",
    "    for key in prior_dict.keys():\n",
    "        sub_dict = prior_dict[key]\n",
    "\n",
    "    ## Unconstrained\n",
    "        if sub_dict['type'] == 'unconstrained':\n",
    "            unconstr_pars.extend(pm.Normal('Unconstrained', mu=sub_dict['input'][0], sigma=sub_dict['input'][1]))\n",
    "        pass\n",
    "\n",
    "    ## Normal and Poisson constraints            \n",
    "        if sub_dict['type'] == 'normal':\n",
    "            norm_mu.append(sub_dict['input'][0])\n",
    "            norm_sigma.append(sub_dict['input'][1])\n",
    "        \n",
    "        if sub_dict['type'] == 'poisson':\n",
    "            poiss_alpha.append(sub_dict['input'][0])\n",
    "            poiss_beta.append(sub_dict['input'][1])\n",
    "\n",
    "    if np.array(norm_mu, dtype=object).size != 0:\n",
    "        norm_pars.extend(pm.Normal('Normals', mu=list(np.concatenate(norm_mu)), sigma=list(np.concatenate(norm_sigma))))\n",
    "\n",
    "    if np.array(poiss_alpha, dtype=object).size != 0:\n",
    "        poiss_pars.extend(pm.Gamma('Gammas', alpha=list(np.concatenate(poiss_alpha)), beta=list(np.concatenate(poiss_beta))))\n",
    "\n",
    "    pars = []\n",
    "    for i in [unconstr_pars, norm_pars, poiss_pars]:\n",
    "        i = np.array(i)\n",
    "        if i.size != 0:\n",
    "            pars.append(i)\n",
    "    pars = np.concatenate(pars)\n",
    "    target = prepare_inference.get_target(model)\n",
    "    final = pt.as_tensor_variable(pars[target.argsort()].tolist())\n",
    "\n",
    "print(final.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model():\n",
    "    \n",
    "#     mu = grad_op(final, at.constant([1.0, 1.0, 1.0])).eval()\n",
    "#     main = pm.Normal(\"main\", mu=mu)#, observed=obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
