{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "# import aesara\n",
    "import aesara.tensor as at\n",
    "from aesara.graph.op import Op\n",
    "from aesara.link.jax.dispatch import jax_funcify\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(1, '/Users/malinhorstmann/Documents/pyhf_pymc/src')\n",
    "import MH_inference\n",
    "import HMC_inference\n",
    "import prepare_inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple pyhf model\n",
    "dummy_model = pyhf.Model(\n",
    "    {'channels': [{'name': 'singlechannel',\n",
    "    'samples': [\n",
    "    {'name': 'signal',\n",
    "     'data': [6, 6, 3],\n",
    "     'modifiers': [\n",
    "         {'name': 'mu', 'type': 'normfactor', 'data': None}]},\n",
    "\n",
    "    {'name': 'background',\n",
    "     'data': [55, 55, 55],''\n",
    "     'modifiers': [\n",
    "        ## Staterror / Normal\n",
    "        {\"name\": \"my_staterror\",\"type\": \"staterror\",\"data\": [2.0, 2.0, 2.4],},\n",
    "        ## Lumi / Normal\n",
    "        {'name': 'lumi', 'type': 'lumi', 'data': None},\n",
    "        ## Correlated / Normal\n",
    "        {'name': 'corr_bkg', 'type': 'histosys','data': {'hi_data': [65, 56, 67], 'lo_data': [40, 40, 43]}},\n",
    "        {'name': 'corr_bkg1', 'type': 'histosys','data': {'hi_data': [65, 65, 66], 'lo_data': [40, 40, 40]}},\n",
    "        {'name': 'corr_bkg2', 'type': 'histosys','data': {'hi_data': [66, 65, 60], 'lo_data': [40, 40, 39]}},\n",
    "        ## Uncorrelated / Poisson\n",
    "        # {'name': 'uncorr_bkg', 'type': 'shapesys','data': [7, 8, 7.17]},\n",
    "        # {'name': 'uncorr_bkg1', 'type': 'shapesys','data': [7, 8, 6.7]},\n",
    "        # {'name': 'uncorr_bkg2', 'type': 'shapesys','data': [7.27, 9, 7]},\n",
    "        \n",
    "         ]},    \n",
    "                                 \n",
    "    ]},\n",
    "    ],\n",
    "    \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"lumi\",\n",
    "                \"auxdata\": [1.0],\n",
    "                \"sigmas\": [0.017],\n",
    "                \"bounds\": [[0.915, 1.085]],\n",
    "                \"inits\": [1.0],\n",
    "            }\n",
    "        ],}\n",
    ")\n",
    "\n",
    "dummy_nBins = len(dummy_model.expected_actualdata(dummy_model.config.suggested_init()))\n",
    "\n",
    "### Observations\n",
    "dummy_obs = dummy_model.expected_actualdata(dummy_model.config.suggested_init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SRee_SRmm_Srem.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "DL_model = workspace.model()\n",
    "DL_obs = workspace.data(DL_model, include_auxdata=False)\n",
    "DL_nBins = len(DL_model.expected_actualdata(DL_model.config.suggested_init()))\n",
    "\n",
    "\n",
    "with open('ttbar_ljets_xsec_inclusive_pruned.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "ttbar_model = workspace.model()\n",
    "ttbar_obs = workspace.data(ttbar_model, include_auxdata=False)\n",
    "ttbar_nBins = len(ttbar_model.expected_actualdata(ttbar_model.config.suggested_init()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with DL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processedData(p):\n",
    "    # a = jnp.stack([jax.jit(model.expected_actualdata(p))[i] for i in range(nBins)])\n",
    "    a = jnp.stack([DL_model.expected_actualdata(p)[i] for i in range(DL_nBins)])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processedData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m### Appling the Op to model.expected_actualdata\u001b[39;00m\n\u001b[1;32m      2\u001b[0m op, grad_op \u001b[39m=\u001b[39m HMC_inference\u001b[39m.\u001b[39mmake_op(\n\u001b[0;32m----> 3\u001b[0m     processedData,\n\u001b[1;32m      4\u001b[0m     (at\u001b[39m.\u001b[39mTensorType(dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(DL_model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpar_map),)),),\n\u001b[1;32m      5\u001b[0m     (at\u001b[39m.\u001b[39mTensorType(dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, shape\u001b[39m=\u001b[39m(DL_nBins,)),),\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.01\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(DL_model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpar_names))\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      9\u001b[0m pars \u001b[39m=\u001b[39m at\u001b[39m.\u001b[39mas_tensor_variable(a)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processedData' is not defined"
     ]
    }
   ],
   "source": [
    "### Appling the Op to model.expected_actualdata\n",
    "op, grad_op = HMC_inference.make_op(\n",
    "    processedData,\n",
    "    (at.TensorType(dtype=np.float64, shape=(len(DL_model.config.par_map),)),),\n",
    "    (at.TensorType(dtype=np.float64, shape=(DL_nBins,)),),\n",
    ")\n",
    "\n",
    "a = np.linspace(0.01, 1, len(DL_model.config.par_names)).tolist()\n",
    "pars = at.as_tensor_variable(a)\n",
    "grad_op(pars, at.constant([1.0, 1.0, 1.0])).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstr_dict = {\n",
    "    'uncon1': {'type': 'unconstrained', 'type2': 'normal', 'input': [[1], [0.1]]}\n",
    "    }\n",
    "\n",
    "\n",
    "prior_dict = prepare_inference.prepare_priors(DL_model, unconstr_dict)\n",
    "\n",
    "    # dictionary with keys 'model', 'obs', 'priors', 'precision'\n",
    "prepared_model = prepare_inference.prepare_model(model=DL_model, observations=DL_obs, precision=0.10, priors=prior_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the `sampling()` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, (18,))\n"
     ]
    }
   ],
   "source": [
    "unconstr_pars, norm_pars, poiss_pars = [], [], []\n",
    "norm_mu, norm_sigma = [], []\n",
    "poiss_alpha, poiss_beta = [], []\n",
    "model = prepared_model['model']\n",
    "obs = prepared_model['obs']\n",
    "prior_dict = prepared_model['priors']\n",
    "precision = prepared_model['precision']\n",
    "\n",
    "with pm.Model():\n",
    "    \n",
    "    for key in prior_dict.keys():\n",
    "        sub_dict = prior_dict[key]\n",
    "\n",
    "    ## Unconstrained\n",
    "        if sub_dict['type'] == 'unconstrained':\n",
    "            unconstr_pars.extend(pm.Normal('Unconstrained', mu=sub_dict['input'][0], sigma=sub_dict['input'][1]))\n",
    "        pass\n",
    "\n",
    "    ## Normal and Poisson constraints            \n",
    "        if sub_dict['type'] == 'normal':\n",
    "            norm_mu.append(sub_dict['input'][0])\n",
    "            norm_sigma.append(sub_dict['input'][1])\n",
    "        \n",
    "        if sub_dict['type'] == 'poisson':\n",
    "            poiss_alpha.append(sub_dict['input'][0])\n",
    "            poiss_beta.append(sub_dict['input'][1])\n",
    "\n",
    "    if np.array(norm_mu, dtype=object).size != 0:\n",
    "        norm_pars.extend(pm.Normal('Normals', mu=list(np.concatenate(norm_mu)), sigma=list(np.concatenate(norm_sigma))))\n",
    "\n",
    "    if np.array(poiss_alpha, dtype=object).size != 0:\n",
    "        poiss_pars.extend(pm.Gamma('Gammas', alpha=list(np.concatenate(poiss_alpha)), beta=list(np.concatenate(poiss_beta))))\n",
    "\n",
    "    pars = []\n",
    "    for i in [unconstr_pars, norm_pars, poiss_pars]:\n",
    "        i = np.array(i)\n",
    "        if i.size != 0:\n",
    "            pars.append(i)\n",
    "    pars = np.concatenate(pars)\n",
    "    target = prepare_inference.get_target(model)\n",
    "    final = pt.as_tensor_variable(pars[target.argsort()].tolist())\n",
    "\n",
    "print(final.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model():\n",
    "    \n",
    "#     mu = grad_op(final, at.constant([1.0, 1.0, 1.0])).eval()\n",
    "#     main = pm.Normal(\"main\", mu=mu)#, observed=obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SRee_SRmm_Srem.json') as serialized:\n",
    "    spec = json.load(serialized)\n",
    "\n",
    "workspace = pyhf.Workspace(spec)\n",
    "model = workspace.model()\n",
    "obs = workspace.data(model, include_auxdata=False)\n",
    "nBins = len(model.expected_actualdata(model.config.suggested_init()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "from pytensor.graph import Apply, Op\n",
    "from pytensor.link.jax.dispatch import jax_funcify\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import pymc as pm\n",
    "import pymc.sampling.jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_op_jax(x):\n",
    "    return jnp.exp(x)\n",
    "\n",
    "jitted_custom_op_jax = jax.jit(custom_op_jax)\n",
    "\n",
    "jitted_custom_op_jax(np.arange(3))\n",
    "\n",
    "\n",
    "def vjp_custom_op_jax(x, gz):\n",
    "    _, vjp_fn = jax.vjp(custom_op_jax, x)\n",
    "    return vjp_fn(gz)[0]\n",
    "\n",
    "jitted_vjp_custom_op_jax = jax.jit(vjp_custom_op_jax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument '<CompiledFunction of <function custom_expData at 0x288db8700>>' of type <class 'jaxlib.xla_extension.CompiledFunction'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     _,back \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvjp(func,fwd_inputs)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m back(vector)\n\u001b[0;32m----> 6\u001b[0m vjp_func(custom_expData, np\u001b[39m.\u001b[39;49marange(\u001b[39m18\u001b[39;49m), at\u001b[39m.\u001b[39;49mconstant([\u001b[39m1.0\u001b[39;49m, \u001b[39m1.0\u001b[39;49m, \u001b[39m1.0\u001b[39;49m]))\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyhf_pymc/lib/python3.9/site-packages/jax/_src/dispatch.py:627\u001b[0m, in \u001b[0;36mcheck_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_arg\u001b[39m(arg):\n\u001b[1;32m    626\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(arg, core\u001b[39m.\u001b[39mTracer) \u001b[39mor\u001b[39;00m _valid_jaxtype(arg)):\n\u001b[0;32m--> 627\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(arg)\u001b[39m}\u001b[39;00m\u001b[39m is not a valid \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    628\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mJAX type.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument '<CompiledFunction of <function custom_expData at 0x288db8700>>' of type <class 'jaxlib.xla_extension.CompiledFunction'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def vjp_func(func,fwd_inputs, vector):\n",
    "    _,back = jax.vjp(func,fwd_inputs)\n",
    "    return back(vector)\n",
    "\n",
    "vjp_func(custom_expData, np.arange(18), at.constant([1.0, 1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'expected_actualdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     expData \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mstack([model\u001b[39m.\u001b[39mexpected_actualdata(parameters)[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nBins)])\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m expData\n\u001b[0;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(custom_expData(np\u001b[39m.\u001b[39;49marange(\u001b[39m18\u001b[39;49m)))\n\u001b[1;32m     10\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mjit\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvjp_custom_expData\u001b[39m(parameters, vector):\n\u001b[1;32m     12\u001b[0m     _, vjp_fn \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvjp(custom_expData, parameters)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[68], line 4\u001b[0m, in \u001b[0;36mcustom_expData\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcustom_expData\u001b[39m(parameters):\n\u001b[1;32m      3\u001b[0m     nBins \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     expData \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mstack([model\u001b[39m.\u001b[39mexpected_actualdata(parameters)[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nBins)])\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m expData\n",
      "Cell \u001b[0;32mIn[68], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcustom_expData\u001b[39m(parameters):\n\u001b[1;32m      3\u001b[0m     nBins \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     expData \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mstack([model\u001b[39m.\u001b[39;49mexpected_actualdata(parameters)[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nBins)])\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m expData\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'expected_actualdata'"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def custom_expData(parameters):\n",
    "    nBins = 3\n",
    "    expData = jnp.stack([model.expected_actualdata(parameters)[i] for i in range(nBins)])\n",
    "\n",
    "    return expData\n",
    "\n",
    "print(custom_expData(np.arange(18)))\n",
    "\n",
    "@jax.jit\n",
    "def vjp_custom_expData(parameters, vector):\n",
    "    _, vjp_fn = jax.vjp(custom_expData, parameters)\n",
    "    return vjp_fn(vector)\n",
    "\n",
    "\n",
    "print(vjp_custom_expData(np.arange(18), at.constant([1.0, 1.0, 1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOp(Op):\n",
    "    # def make_node(self, x):\n",
    "    #     # Create a PyTensor node specifying the number and type of inputs and outputs\n",
    "\n",
    "    #     # We convert the input into a PyTensor tensor variable\n",
    "    #     inputs = [pt.as_tensor_variable(x)]\n",
    "    #     # Output has the same type and shape as `x`\n",
    "    #     outputs = [inputs[0].type()]\n",
    "    #     return Apply(self, inputs, outputs)\n",
    "\n",
    "    # def perform(self, node, inputs, outputs):\n",
    "    #     # Evaluate the Op result for a specific numerical input\n",
    "\n",
    "    #     # The inputs are always wrapped in a list\n",
    "    #     (x,) = inputs\n",
    "    #     result = jitted_custom_op_jax(x)\n",
    "    #     # The results should be assigned inplace to the nested list\n",
    "    #     # of outputs provided by PyTensor. If you have multiple\n",
    "    #     # outputs and results, you should assign each at outputs[i][0]\n",
    "    #     outputs[0][0] = np.asarray(result, dtype=\"float64\")\n",
    "\n",
    "    # def grad(self, inputs, output_gradients):\n",
    "    #     # Create a PyTensor expression of the gradient\n",
    "    #     (x,) = inputs\n",
    "    #     (gz,) = output_gradients\n",
    "    #     # We reference the VJP Op created below, which encapsulates\n",
    "    #     # the gradient operation\n",
    "    #     return [vjp_custom_op(x, gz)]\n",
    "        __props__ = (\"jax_vjp_func\",)\n",
    "\n",
    "        def __init__(self):\n",
    "            self.jax_vjp_func = vjp_func\n",
    "            self.itypes = itypes + otypes\n",
    "            self.otypes = itypes\n",
    "            super().__init__()\n",
    "\n",
    "        def perform(self, node, inputs, outputs):\n",
    "\n",
    "            results = self.jax_vjp_func(*(jnp.asarray(x) for x in inputs))\n",
    "\n",
    "            if not isinstance(results, (list, tuple)):\n",
    "                results = (results,)\n",
    "\n",
    "            for i, r in enumerate(results):\n",
    "                outputs[i][0] = np.asarray(r)\n",
    "\n",
    "\n",
    "class VJPCustomOp(Op):\n",
    "    def make_node(self, x, gz):\n",
    "        # Make sure the two inputs are tensor variables\n",
    "        inputs = [pt.as_tensor_variable(x), pt.as_tensor_variable(gz)]\n",
    "        # Output has the shape type and shape as the first input\n",
    "        outputs = [inputs[0].type()]\n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (x, gz) = inputs\n",
    "        result = jitted_vjp_custom_op_jax(x, gz)\n",
    "        outputs[0][0] = np.asarray(result, dtype=\"float64\")\n",
    "\n",
    "# Instantiate the Ops\n",
    "custom_op = CustomOp()\n",
    "vjp_custom_op = VJPCustomOp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytensor.gradient.verify_grad(custom_op, (np.arange(5, dtype=\"float64\"),), rng=np.random.default_rng())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 200 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [x, y, z]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 200 draw iterations (4_000 + 800 draws total) took 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    x = pm.Normal(\"x\", shape=(3,))\n",
    "    y = pm.Normal(\"y\", mu=custom_op(x))  # HERE IS WHERE WE USE THE CUSTOM OP!\n",
    "    z = pm.Normal(\"z\", y)\n",
    "\n",
    "    a = pm.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
