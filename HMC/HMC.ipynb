{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import pytensor \n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import scipy.stats as sps\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')\n",
    "\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "import aesara\n",
    "import aesara.tensor as at\n",
    "from aesara.graph.op import Op\n",
    "from aesara.link.jax.dispatch import jax_funcify\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using JAX and aesara for HMC sampling of the model.expected_actualdata()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose model\n",
    "n = \"DisplacedLeptons\"\n",
    "\n",
    "if n == \"ttbar\":\n",
    "    with open(\"/Users/malinhorstmann/Documents/pyhf_pymc/PredictiveChecks/ttbar_ljets_xsec_inclusive_pruned.json\") as serialized:\n",
    "        spec = json.load(serialized)\n",
    "    nBins = 37\n",
    "\n",
    "if n == \"DisplacedLeptons\":\n",
    "    with open(\"/Users/malinhorstmann/Documents/pyhf_pymc/PredictiveChecks/SRee_SRmm_Srem.json\") as serialized:\n",
    "        spec = json.load(serialized)\n",
    "    nBins = 3\n",
    "\n",
    "\n",
    "### Create pyhf model\n",
    "workspace = pyhf.Workspace(spec)\n",
    "\n",
    "model = workspace.model()\n",
    "\n",
    "### Observations\n",
    "obs = model.expected_data(model.config.suggested_init())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess the model.expected_actualdata\n",
    "def processedData(p):\n",
    "    # a = jnp.stack([jax.jit(model.expected_actualdata(p))[i] for i in range(nBins)])\n",
    "    a = jnp.stack([model.expected_actualdata(p)[i] for i in range(nBins)])\n",
    "    return a\n",
    "\n",
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Op 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aesara.graph.op import Op\n",
    "def make_op(func, itypes, otypes):\n",
    "    @jax.jit\n",
    "    def vjp_func(fwd_inputs, vector):\n",
    "        _,back = jax.vjp(func,fwd_inputs)\n",
    "        return back(vector)\n",
    "\n",
    "    class JaxVJPOp(Op):\n",
    "        __props__ = (\"jax_vjp_func\",)\n",
    "\n",
    "        def __init__(self):\n",
    "            self.jax_vjp_func = vjp_func\n",
    "            self.itypes = itypes + otypes\n",
    "            self.otypes = itypes\n",
    "            super().__init__()\n",
    "\n",
    "        def perform(self, node, inputs, outputs):\n",
    "\n",
    "            results = self.jax_vjp_func(*(jnp.asarray(x) for x in inputs))\n",
    "\n",
    "            if not isinstance(results, (list, tuple)):\n",
    "                results = (results,)\n",
    "\n",
    "            for i, r in enumerate(results):\n",
    "                outputs[i][0] = np.asarray(r)\n",
    "\n",
    "\n",
    "    jax_grad_op = JaxVJPOp()\n",
    "                \n",
    "    @jax_funcify.register(JaxVJPOp)\n",
    "    def jax_funcify_JaxGradOp(op):\n",
    "        return op.jax_vjp_func\n",
    "\n",
    "    @jax.jit\n",
    "    def fwd_func(fwd_inputs):\n",
    "        return func(fwd_inputs)\n",
    "    \n",
    "    class JaxOp(Op):\n",
    "        __props__ = (\"fwd_func\",)\n",
    "\n",
    "        def __init__(self):\n",
    "            self.fwd_func = fwd_func\n",
    "            self.itypes = itypes\n",
    "            self.otypes = otypes\n",
    "            super().__init__()\n",
    "\n",
    "        def perform(self, node, inputs, outputs):\n",
    "            results = self.fwd_func(*(jnp.asarray(x) for x in inputs))\n",
    "            if len(outputs) == 1:\n",
    "                outputs[0][0] = np.asarray(results)\n",
    "                return\n",
    "            for i, r in enumerate(results):\n",
    "                outputs[i][0] = np.asarray(r)\n",
    "\n",
    "        def grad(self, inputs, vectors):\n",
    "            return [jax_grad_op(inputs[0], vectors[0])]\n",
    "\n",
    "    @jax_funcify.register(JaxOp)\n",
    "    def jax_funcify_JaxOp(op):\n",
    "        return op.fwd_func\n",
    "\n",
    "    jax_op = JaxOp()\n",
    "    \n",
    "    return jax_op, jax_grad_op"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.22021957e-02,  7.65032179e-03,  9.50228104e-02,  2.61874674e-05,\n",
       "       -3.44132928e-05, -4.50589683e-06,  5.89919525e-06,  2.11944936e-05,\n",
       "       -7.58614712e-06,  1.74513037e-02,  1.90408675e-01, -2.65716482e-05,\n",
       "       -3.39078458e-06,  4.72531697e-06,  3.81544561e-06,  1.61576618e-05,\n",
       "        4.09487406e-06, -9.99838836e-07])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Appling the Op to model.expected_actualdata\n",
    "op, grad_op = make_op(\n",
    "    processedData,\n",
    "    (at.TensorType(dtype=np.float64, shape=(len(model.config.par_map),)),),\n",
    "    (at.TensorType(dtype=np.float64, shape=(nBins,)),),\n",
    ")\n",
    "\n",
    "### Test for some array of input parameters\n",
    "a = np.linspace(0.01, 1, len(model.config.par_names)).tolist()\n",
    "pars = at.as_tensor_variable(a)\n",
    "grad_op(pars, at.constant([1.0, 1.0, 1.0])).eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Op 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primals: (Array(2., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True))\n",
      "vjp: [Array(4., dtype=float64, weak_type=True), Array(6., dtype=float64, weak_type=True), Array(4., dtype=float64, weak_type=True)]\n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "    return x[0]**2 + x[1]**3, x[2]**4\n",
    "\n",
    "eval_point = [1.0, 1.0, 1.0]\n",
    "\n",
    "primals, func_vjp = jax.vjp(func, eval_point)\n",
    "\n",
    "vjp1 = func_vjp((2.0, 1.0))\n",
    "\n",
    "print(f'primals: {primals}')\n",
    "print(f'vjp: {vjp1[0]}' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "- .. Attention: Using `pm.Normal()` tensor variables as input to `grad_op` does not work yet.\n",
    "- `op` yields approximatly the same results as the sampling from the normal `Op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [main]\n",
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 0 seconds.\n"
     ]
    }
   ],
   "source": [
    "### Opening the pyMC model space\n",
    "start_time = time.time()\n",
    "with pm.Model():\n",
    "    ## Parameters\n",
    "    a = np.linspace(0.01, 1, len(model.config.par_names)).tolist()\n",
    "    pars = at.as_tensor_variable(a)\n",
    "\n",
    "    ## Model for the logpdf()\n",
    "    # main = pm.Normal(\"main\", mu=grad_op(pars, at.constant([1.0, 1.0, 1.0])).eval(), sigma=1)#, observed=obs)\n",
    "    main = pm.Normal(\"main\", mu=op(pars).eval(), sigma=0.001)#, observed=obs)\n",
    "\n",
    "    ## Sampling ...\n",
    "    post_data = pm.sample(500, progressbar=False)\n",
    "    # prior_data = pm.sample_prior_predictive(500)\n",
    "    # post_pred = pm.sample_posterior_predictive(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>main[0]</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main[1]</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main[2]</th>\n",
       "      <td>0.208</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "main[0]  0.472  0.001   0.471    0.474        0.0      0.0    3020.0   \n",
       "main[1]  0.014  0.001   0.013    0.016        0.0      0.0    3195.0   \n",
       "main[2]  0.208  0.001   0.206    0.210        0.0      0.0    2392.0   \n",
       "\n",
       "         ess_tail  r_hat  \n",
       "main[0]    1479.0    1.0  \n",
       "main[1]    1623.0    1.0  \n",
       "main[2]    1678.0    1.0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(post_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with \"normal\" Op\n",
    "\n",
    "... yields approximatly the same as the `op, grad_op = make_op()` for the expected bin cound, i.e. `op`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aesara.graph.op import Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class that creates the model Op\n",
    "class Op(pt.Op):\n",
    "    itypes = [pt.dvector]  # Expects a vector of parameter values\n",
    "    otypes = [pt.dvector]  # Outputs a vector of values (the model.expected_actualdata)\n",
    "\n",
    "    def __init__(self, name, func):\n",
    "        ## Add inputs as class attributes\n",
    "        self.func = func\n",
    "        self.name = name\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        ## Method that is used when calling the Op\n",
    "        (theta,) = inputs  # Contains my variables\n",
    "\n",
    "        ## Calling input function (in our case the model.expected_actualdata)\n",
    "        result = self.func(theta)\n",
    "\n",
    "        ## Output values of model.expected_actualdata\n",
    "        outputs[0][0] = np.asarray(result, dtype=node.outputs[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [n]\n",
      ">NUTS: [main]\n",
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "### Applying the Op with arguments (function, name)\n",
    "mainOp = Op(\"mainOp\", jax.jit(model.expected_actualdata))\n",
    "# mainOp = Op(\"mainOp\", model.expected_actualdata)\n",
    "\n",
    "### Opening the PyMC model space\n",
    "with pm.Model():\n",
    "    pars = []\n",
    "    mu = []\n",
    "    sigma = []\n",
    "\n",
    "    ## Stitching\n",
    "    for i in range(18):\n",
    "            mu.append(a[i])\n",
    "            sigma.append(0.0001)\n",
    "    pars.extend(pm.Normal('n', mu=mu, sigma=sigma))\n",
    "\n",
    "    pars = np.concatenate([pars])\n",
    "    final = pt.as_tensor_variable(pars.tolist())\n",
    "\n",
    "    ## Model for the model.expected_actualdata()\n",
    "        # Attention: pm.Poisson breaks down, as \\lambda < 0 occasionally if mu=0.0\n",
    "    main = pm.Normal(\"main\", mu=mainOp(final))#observed=obs)\n",
    "\n",
    "    ## Sampling\n",
    "    post_data = pm.sample(500, progressbar=False)\n",
    "    # prior_data = pm.sample_prior_predictive(500)\n",
    "    # post_pred = pm.sample_posterior_predictive(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n[0]</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>231.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[1]</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[2]</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>318.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[3]</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>258.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[4]</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>244.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[5]</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>252.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[6]</th>\n",
       "      <td>0.359</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>252.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[7]</th>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>333.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[8]</th>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[9]</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>299.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[10]</th>\n",
       "      <td>0.592</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>143.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[11]</th>\n",
       "      <td>0.651</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[12]</th>\n",
       "      <td>0.709</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>184.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[13]</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>192.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[14]</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[15]</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[16]</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n[17]</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>198.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main[0]</th>\n",
       "      <td>0.505</td>\n",
       "      <td>1.016</td>\n",
       "      <td>-1.297</td>\n",
       "      <td>2.464</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.022</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main[1]</th>\n",
       "      <td>0.005</td>\n",
       "      <td>1.016</td>\n",
       "      <td>-1.840</td>\n",
       "      <td>1.959</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main[2]</th>\n",
       "      <td>0.246</td>\n",
       "      <td>1.029</td>\n",
       "      <td>-1.608</td>\n",
       "      <td>2.149</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.021</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "n[0]     0.010  0.000   0.010    0.010      0.000    0.000     231.0   \n",
       "n[1]     0.068  0.000   0.068    0.068      0.000    0.000     180.0   \n",
       "n[2]     0.126  0.000   0.126    0.127      0.000    0.000     318.0   \n",
       "n[3]     0.185  0.000   0.185    0.185      0.000    0.000     258.0   \n",
       "n[4]     0.243  0.000   0.243    0.243      0.000    0.000     244.0   \n",
       "n[5]     0.301  0.000   0.301    0.301      0.000    0.000     252.0   \n",
       "n[6]     0.359  0.000   0.359    0.360      0.000    0.000     252.0   \n",
       "n[7]     0.418  0.000   0.417    0.418      0.000    0.000     333.0   \n",
       "n[8]     0.476  0.000   0.476    0.476      0.000    0.000     270.0   \n",
       "n[9]     0.534  0.000   0.534    0.534      0.000    0.000     299.0   \n",
       "n[10]    0.592  0.000   0.592    0.593      0.000    0.000     143.0   \n",
       "n[11]    0.651  0.000   0.650    0.651      0.000    0.000     322.0   \n",
       "n[12]    0.709  0.000   0.709    0.709      0.000    0.000     184.0   \n",
       "n[13]    0.767  0.000   0.767    0.767      0.000    0.000     192.0   \n",
       "n[14]    0.825  0.000   0.825    0.825      0.000    0.000      97.0   \n",
       "n[15]    0.884  0.000   0.883    0.884      0.000    0.000     225.0   \n",
       "n[16]    0.942  0.000   0.942    0.942      0.000    0.000     114.0   \n",
       "n[17]    1.000  0.000   1.000    1.000      0.000    0.000     198.0   \n",
       "main[0]  0.505  1.016  -1.297    2.464      0.020    0.022    2658.0   \n",
       "main[1]  0.005  1.016  -1.840    1.959      0.022    0.022    2131.0   \n",
       "main[2]  0.246  1.029  -1.608    2.149      0.020    0.021    2687.0   \n",
       "\n",
       "         ess_tail  r_hat  \n",
       "n[0]        206.0   1.02  \n",
       "n[1]        330.0   1.02  \n",
       "n[2]        387.0   1.01  \n",
       "n[3]        244.0   1.02  \n",
       "n[4]        283.0   1.03  \n",
       "n[5]        205.0   1.01  \n",
       "n[6]        310.0   1.03  \n",
       "n[7]        222.0   1.03  \n",
       "n[8]        242.0   1.03  \n",
       "n[9]        325.0   1.01  \n",
       "n[10]       125.0   1.03  \n",
       "n[11]       207.0   1.03  \n",
       "n[12]       279.0   1.04  \n",
       "n[13]       135.0   1.05  \n",
       "n[14]       224.0   1.05  \n",
       "n[15]       142.0   1.01  \n",
       "n[16]       189.0   1.03  \n",
       "n[17]       153.0   1.04  \n",
       "main[0]    1279.0   1.00  \n",
       "main[1]    1435.0   1.00  \n",
       "main[2]    1695.0   1.00  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44009b16d2e2eba83b85bbf6c42594a891bd8e72107454e9c42af2692a5b5216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
