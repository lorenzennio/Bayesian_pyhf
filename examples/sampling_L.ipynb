{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import jax.config as config\n",
    "config.update('jax_enable_x64', True)\n",
    "import numpy as np\n",
    "\n",
    "import pytensor\n",
    "from pytensor import tensor as pt\n",
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph import Apply, Op\n",
    "\n",
    "import jax\n",
    "from jax import grad, jit, vmap, value_and_grad, random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import pyhf\n",
    "pyhf.set_backend('jax')\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([60., 60., 60., 60., 60.], dtype=float64), [0.0, 1.0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "obs = jnp.array([70.]*N)\n",
    "model = pyhf.simplemodels.correlated_background([10]*N,[50]*N, [45]*N, [55]*N)\n",
    "model.expected_actualdata(model.config.suggested_init()),model.config.suggested_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VJPOp(pt.Op):\n",
    "    itypes = [pt.dvector,pt.dvector]  \n",
    "    otypes = [pt.dvector]\n",
    "\n",
    "    def __init__(self, vjp_func):\n",
    "        self.vjp_func = vjp_func\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (at, vector) = inputs\n",
    "        results = self.vjp_func(at, vector)\n",
    "\n",
    "        if len(outputs) == 1:\n",
    "            outputs[0][0] = np.asarray(results, dtype = np.float64)\n",
    "\n",
    "        for i, r in enumerate(results):\n",
    "            outputs[i][0] = np.asarray(r, dtype = np.float64)\n",
    "\n",
    "\n",
    "class ExpDataOp(pt.Op):\n",
    "    itypes = [pt.dvector]  \n",
    "    otypes = [pt.dvector]\n",
    "\n",
    "    def __init__(self, fwd_func):\n",
    "        self.fwd_func = fwd_func\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (parameters, ) = inputs\n",
    "        results = self.fwd_func(parameters)\n",
    "\n",
    "        if len(outputs) == 1:\n",
    "                outputs[0][0] = np.asarray(results, dtype = np.float64)\n",
    "                return\n",
    "        for i, r in enumerate(results):\n",
    "                outputs[i][0] = np.asarray(r, dtype = np.float64)\n",
    "\n",
    "    def grad(self, at_vector, vector):\n",
    "        return [vjp_op(at_vector[0],vector[0])]\n",
    "    \n",
    "def _pyhf_forward(x):\n",
    "    return model.expected_actualdata(x)\n",
    "\n",
    "pyhf_fwd_func = jax.jit(_pyhf_forward)\n",
    "pyhf_vjp_func = jax.jit(lambda at, vector: jax.vjp(_pyhf_forward, at)[1](vector))\n",
    "                \n",
    "fwd_op = ExpDataOp(pyhf_fwd_func)\n",
    "vjp_op = VJPOp(pyhf_vjp_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf_pymc\n",
    "\n",
    "from pyhf_pymc import prepare_inference\n",
    "\n",
    "def priors2pymc(prepared_model):\n",
    "    unconstr_pars, norm_pars, poiss_pars = [], [], []\n",
    "    norm_mu, norm_sigma = [], []\n",
    "    poiss_alpha, poiss_beta = [], []\n",
    "    model = prepared_model['model']\n",
    "    obs = prepared_model['obs']\n",
    "    prior_dict = prepared_model['priors']\n",
    "    precision = prepared_model['precision']\n",
    "        \n",
    "    for key in prior_dict.keys():\n",
    "        sub_dict = prior_dict[key]\n",
    "\n",
    "    ## Unconstrained\n",
    "        if sub_dict['type'] == 'unconstrained':\n",
    "            unconstr_pars.extend(pm.Gamma('Unconstrained', alpha=sub_dict['input'][0], beta=sub_dict['input'][1]))\n",
    "        pass\n",
    "\n",
    "    ## Normal and Poisson constraints            \n",
    "        if sub_dict['type'] == 'normal':\n",
    "            norm_mu.append(sub_dict['input'][0])\n",
    "            norm_sigma.append(sub_dict['input'][1])\n",
    "\n",
    "        if sub_dict['type'] == 'poisson':\n",
    "            poiss_alpha.append(sub_dict['input'][0])\n",
    "            poiss_beta.append(sub_dict['input'][1])\n",
    "\n",
    "    if np.array(norm_mu, dtype=object).size != 0:\n",
    "        norm_pars.extend(pm.Normal('Normals', mu=list(np.concatenate(norm_mu)), sigma=list(np.concatenate(norm_sigma))))\n",
    "\n",
    "    if np.array(poiss_alpha, dtype=object).size != 0:\n",
    "        poiss_pars.extend(pm.Gamma('Gammas', alpha=list(np.concatenate(poiss_alpha)), beta=list(np.concatenate(poiss_beta))))\n",
    "\n",
    "    pars = []\n",
    "    for i in [unconstr_pars, norm_pars, poiss_pars]:\n",
    "        i = np.array(i)\n",
    "        if i.size != 0:\n",
    "            pars.append(i)\n",
    "    pars = np.concatenate(pars)\n",
    "    target = prepare_inference.get_target(model)\n",
    "    final = pt.as_tensor_variable(pars[target.argsort()].tolist())\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstr_dict = {\n",
    "    'mu': {'type': 'unconstrained', 'input': [[1.], [1.]]}\n",
    "}\n",
    "prior_dict = prepare_inference.prepare_priors(model, unconstr_dict)\n",
    "prepared_model = prepare_inference.prepare_model(model=model, observations=obs, precision=1, priors=prior_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using advi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence achieved at 4700\n",
      "Interrupted at 4,699 [0%]: Average Loss = 19.7\n",
      "Interrupted at 4,699 [0%]: Average Loss = 19.7\n",
      "Sampling: [Normals, Unconstrained, data]\n",
      "Only 150 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Unconstrained, Normals]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 150 draw iterations (4_000 + 600 draws total) took 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model():\n",
    "    pars = priors2pymc(prepared_model)    \n",
    "    params = pm.Deterministic('params',pars)\n",
    "    expected = pm.Deterministic('expected',fwd_op(params))\n",
    "    data = pm.Poisson('data', expected, observed=obs)\n",
    "\n",
    "    pm.init_nuts(init='advi')\n",
    "    step = pm.Metropolis()\n",
    "\n",
    "    prior_pred = pm.sample_prior_predictive(150)\n",
    "    post_data = pm.sample(150,  chains = 4)\n",
    "    post_pred = pm.sample_posterior_predictive(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malinhorstmann/anaconda3/envs/pyhf_pymc/lib/python3.9/site-packages/arviz/stats/stats.py:1351: UserWarning: Selecting first found group: posterior_predictive\n",
      "  warnings.warn(f\"Selecting first found group: {data.groups()[0]}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data[0]</th>\n",
       "      <td>69.483</td>\n",
       "      <td>9.127</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.262</td>\n",
       "      <td>608.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data[1]</th>\n",
       "      <td>68.877</td>\n",
       "      <td>9.143</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.291</td>\n",
       "      <td>479.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data[2]</th>\n",
       "      <td>69.275</td>\n",
       "      <td>9.100</td>\n",
       "      <td>54.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.249</td>\n",
       "      <td>675.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data[3]</th>\n",
       "      <td>69.038</td>\n",
       "      <td>9.372</td>\n",
       "      <td>50.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.298</td>\n",
       "      <td>488.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data[4]</th>\n",
       "      <td>68.998</td>\n",
       "      <td>9.008</td>\n",
       "      <td>53.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.275</td>\n",
       "      <td>539.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "data[0]  69.483  9.127    50.0     85.0      0.370    0.262     608.0   \n",
       "data[1]  68.877  9.143    50.0     85.0      0.411    0.291     479.0   \n",
       "data[2]  69.275  9.100    54.0     87.0      0.351    0.249     675.0   \n",
       "data[3]  69.038  9.372    50.0     84.0      0.421    0.298     488.0   \n",
       "data[4]  68.998  9.008    53.0     86.0      0.389    0.275     539.0   \n",
       "\n",
       "         ess_tail  r_hat  \n",
       "data[0]     558.0   1.00  \n",
       "data[1]     393.0   1.01  \n",
       "data[2]     590.0   1.00  \n",
       "data[3]     440.0   1.01  \n",
       "data[4]     532.0   1.01  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(post_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhf_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
